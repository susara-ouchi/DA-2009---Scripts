{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907b3430",
   "metadata": {},
   "source": [
    "## Creating a Scrapy project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0cbb2c",
   "metadata": {},
   "source": [
    "### Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1970f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install scrapy\n",
    "# ! scrapy startproject quotes_crawler\n",
    "# ! cd quotes_crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffe6d6d",
   "metadata": {},
   "source": [
    "Now Scrapy will set up a full project within the folder \"quotes_crawler\" and add some setup and basic files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be32d64",
   "metadata": {},
   "source": [
    "### Creating the scraper / crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9694be47",
   "metadata": {},
   "source": [
    "Inside quotes_crawler/spiders/quotes_spider.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54a3293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\"http://quotes.toscrape.com\"]\n",
    "\n",
    "    def parse(self, response):\n",
    "        # Loop through all quotes on the page\n",
    "        for quote in response.css(\"div.quote\"):\n",
    "            yield {\n",
    "                'text': quote.css(\"span.text::text\").get(),\n",
    "                'author': quote.css(\"small.author::text\").get(),\n",
    "                'tags': quote.css(\"div.tags a.tag::text\").getall()\n",
    "            }\n",
    "\n",
    "        # Follow pagination link\n",
    "        next_page = response.css(\"li.next a::attr(href)\").get()\n",
    "        if next_page:\n",
    "            yield response.follow(next_page, self.parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b1923e",
   "metadata": {},
   "source": [
    "Special notes:\n",
    "\n",
    "- \"yield\" is used to stream multiple items and requests back to Scrapy one at a time, keeping the spider efficient and able to crawl many pages and extract lots of data in a single run.\n",
    "- A single parse call often produces multiple items (like multiple quotes on one page). \"yield\" allows the function to output many items one by one, without exiting the method early.\n",
    "- Using return would stop the function immediately after returning the first item.\n",
    "\n",
    "\n",
    "- Scrapy is built to work with generators: it collects yielded items and requests asynchronously.\n",
    "- Using return would break this flow and not allow Scrapy to handle multiple outputs properly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c53f7b1",
   "metadata": {},
   "source": [
    "### Running the spider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfc388a",
   "metadata": {},
   "source": [
    "To simply run the crawler and scrape the site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2010ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapy 2.13.3 - no active project\n",
      "\n",
      "The crawl command is not available from this location.\n",
      "These commands are only available from within a project: check, crawl, edit, list, parse.\n",
      "\n",
      "Use \"scrapy\" to see available commands\n"
     ]
    }
   ],
   "source": [
    "!scrapy crawl quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f21d644",
   "metadata": {},
   "source": [
    "To run the craler and extract as a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e713f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !scrapy crawl quotes -o quotes.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865a7e0f",
   "metadata": {},
   "source": [
    "Similarly if you want a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96c6e68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !scrapy crawl quotes -o quotes.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
